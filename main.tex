% !TEX root = tu_template.tex

\subsection*{Part A: Topological features of the aggregated network}

\setlength\LTleft{0pt} % left-align rather than center-set the longtable
\begin{longtable}{@{}l p{0.75\textwidth}@{}}
\textbf{Topological feature} & \textbf{Value} \\ 
\hline
\endhead
N & 123123 \\
L & 123123123 \\ 
p  & 0.111111 \\ 
$E[D]$  & 123123\\
$Var[D]$ & 123123 \\
$\rho_D$ & 123123\\
C & 1123123\\
$E[H]$ & 1123123\\
$H_{max}$ & 1123123\\
$\lambda_1$ & 1123123\\
$\mu_{N-1}$ & 1123123\\
\end{longtable}

\subsection*{Part B: Information spreading on a temporal network}

For $\lambda \neq 0$, the regularization term limits the size of the solution coefficients, trading off the bias of the original solution for a reduction in the variance of the estimator. 
This leads to a reduction of the overall error, as shown in figure \ref{fig:comp}.\\
Moreover, the $\ell1$-norm regularizer leads to a sparse solution, that is, the difference vector $r_- - r_+$ is going to have several zero components. Also the distance between the two representors decreases as $\lambda$ increases.\\
When $\lambda\rightarrow \infty$, the two representors will eventually coincide. This limit behavior is observable for $\lambda > 1000$, approximately.
\subsection*{Part C: \\Influence of temporal network features on information spreading}
\paragraph{3.A}	
so that
\begin{equation*}
\frac{\partial L(r)}{\partial r}=0 \rightarrow 4r-2 = 0 \quad \rightarrow \quad r = \frac{1}{2} \quad \rightarrow \quad (r_-, r_+) = \left(\frac{1}{2}, \frac{1}{2}\right).
\end{equation*}