% !TEX root = tu_template.tex

\subsection*{Part A: Topological features of the aggregated network}

	

\subsection*{Part B: Information spreading on a temporal network}

For $\lambda \neq 0$, the regularization term limits the size of the solution coefficients, trading off the bias of the original solution for a reduction in the variance of the estimator. 
This leads to a reduction of the overall error, as shown in figure \ref{fig:comp}.\\
Moreover, the $\ell1$-norm regularizer leads to a sparse solution, that is, the difference vector $r_- - r_+$ is going to have several zero components. Also the distance between the two representors decreases as $\lambda$ increases.\\
When $\lambda\rightarrow \infty$, the two representors will eventually coincide. This limit behavior is observable for $\lambda > 1000$, approximately.
\subsection*{Part C: \\Influence of temporal network features on information spreading}
\paragraph{3.A}	
so that
\begin{equation*}
\frac{\partial L(r)}{\partial r}=0 \rightarrow 4r-2 = 0 \quad \rightarrow \quad r = \frac{1}{2} \quad \rightarrow \quad (r_-, r_+) = \left(\frac{1}{2}, \frac{1}{2}\right).
\end{equation*}